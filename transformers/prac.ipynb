{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from data.data_loader import load_data, collate_fn, data_process_pipeline\n",
    "from functools import partial\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from trainer import Trainer\n",
    "from model.transformer_encoder import Encoder\n",
    "from model.transformer_decoder import Decoder\n",
    "from model.transformer import Transformer\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pad_sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# hyperparamers\n",
    "num_epochs=2\n",
    "learning_rate=0.001\n",
    "batch_size = 512\n",
    "encoder_embedding_size = 512\n",
    "decoder_embedding_size = 512\n",
    "hidden_size = 1024\n",
    "encoder_n_layers = 2\n",
    "decoder_n_layers = 2\n",
    "encoder_dropout = 0.5\n",
    "decoder_dropout = 0.5\n",
    "teacher_forcing_ratio = 0.5\n",
    "num_heads = 8\n",
    "forward_expansion = 4\n",
    "num_encoders = 6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_data, raw_val_data = load_data(data_path=\"fra.txt\", train_percent=0.8)\n",
    "train_data, eng_vocab, fra_vocab = data_process_pipeline(raw_train_data)\n",
    "val_data, _, _ = data_process_pipeline(\n",
    "    raw_val_data, eng_vocab=eng_vocab, fra_vocab=fra_vocab\n",
    ")\n",
    "\n",
    "# data loader\n",
    "train_loader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=partial(\n",
    "        collate_fn, src_pad_val=eng_vocab[\"<pad>\"], tgt_pad_val=fra_vocab[\"<pad>\"]\n",
    "    ),\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_data,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=partial(\n",
    "        collate_fn, src_pad_val=eng_vocab[\"<pad>\"], tgt_pad_val=fra_vocab[\"<pad>\"]\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(\n",
    "    embed_size=encoder_embedding_size,\n",
    "    num_heads=num_heads,\n",
    "    batch_size=batch_size,\n",
    "    forward_expansion=forward_expansion,\n",
    "    num_encoders=num_encoders,\n",
    "    vocab_size=len(eng_vocab),\n",
    ")\n",
    "\n",
    "decoder = Decoder(\n",
    "    embed_size=decoder_embedding_size,\n",
    "    batch_size=batch_size,\n",
    "    num_heads=num_heads,\n",
    "    forward_expansion=forward_expansion,\n",
    "    num_decoders=num_encoders,\n",
    "    output_size=len(fra_vocab),\n",
    "    teacher_force_ratio=teacher_forcing_ratio,\n",
    "    vocab_size=len(fra_vocab),\n",
    ")\n",
    "transformer=Transformer(encoder=encoder,decoder=decoder,src_pad_idx=eng_vocab[\"<pad>\"],tgt_pad_idx=fra_vocab[\"<pad>\"],device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=fra_vocab['<pad>'])\n",
    "optimizer=torch.optim.Adam(transformer.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    return [token for token in f\"<sos> {text} <eos>\".split(\" \") if token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_pipeline(txt):\n",
    "    if isinstance(txt,str):\n",
    "        txt=[txt]\n",
    "    sent_tokens=[tokenizer(tokens) for tokens in txt]\n",
    "    int_tokens=[eng_vocab.forward(tokens) for tokens in sent_tokens]\n",
    "    src_tensor=[torch.LongTensor(token_list) for token_list in int_tokens]\n",
    "    src=pad_sequence(src_tensor,padding_value=eng_vocab['<pad>'])\n",
    "    return src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer=Trainer(model=transformer,\n",
    "            num_epochs=num_epochs,\n",
    "            batch_size=batch_size,\n",
    "            criterion=criterion,\n",
    "            optimizer=optimizer,\n",
    "            device=device,\n",
    "            print_stats=True,\n",
    "            tgt_vocab=fra_vocab,\n",
    "            text_pipeline=predict_pipeline\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe(model,inputs,pipeline,max_tokens,start_token,tgt_vocab,end_token,device):\n",
    "        with torch.no_grad():\n",
    "            inputs=pipeline(inputs)\n",
    "            inputs=inputs.to(device)\n",
    "            \n",
    "            batch_size=inputs.shape[1]\n",
    "            x_mask=model.src_mask(inputs)\n",
    "            encoder_states=model.encoder(inputs,x_mask)\n",
    "            output_tokens=[]\n",
    "            i=0\n",
    "            for i in range(inputs.shape[1]):\n",
    "                y=torch.LongTensor([start_token]).reshape(-1,1).to(device)\n",
    "                \n",
    "                current_output=[]\n",
    "                k=0\n",
    "                while True:\n",
    "                    \n",
    "                    predictions=model.decoder(y,encoder_states,None)\n",
    "                    \n",
    "                    predictions=predictions[-1,:,:].argmax(-1).unsqueeze(0)\n",
    "                   \n",
    "                    pred_tokens=tgt_vocab.lookup_token(predictions[-1].item())\n",
    "                    \n",
    "                    current_output.append(pred_tokens)\n",
    "                    y=torch.cat((y,predictions),dim=0)\n",
    "                    if end_token==predictions or len(current_output)>=max_tokens:\n",
    "                        break\n",
    "                    k+=1\n",
    "                output_tokens.append(\" \".join(current_output))\n",
    "        return output_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder embeds shape :  torch.Size([27, 1, 512])\n",
      "['L\\'alligator décidiez grasse touchait tourne d\\'entraînement amende avides prioritaire éclairer l\\'infirmier trousse l\\'éventail Relâche-le n\\'attendra parlent-ils d\\'historien Juste connûmes provoque mîmes diapo embarquer douche renseignes papillon agressif insistant \"Tais-toi\" connaissais-tu l\\'envoyer ouvrage m\\'énerves apportez-moi bleu l\\'Inde surannée Monte ressaisir potentiel limpide câlin trouvâmes séparés pointer négocie furent-elles amputé Résides-tu escroc']\n"
     ]
    }
   ],
   "source": [
    "test_txt=\"In this story an old man sets out to ask an Indian king to dig some well in his village when their water runs dry\"\n",
    "expected_translation=\"Dans cette histoire, un vieil homme entreprend de demander à un roi indien de creuser un puits dans son village lorsque leur eau sera à sec.\"\n",
    "predicted_translation=transcribe(\n",
    "    model=transformer,\n",
    "    inputs=test_txt,\n",
    "    pipeline=predict_pipeline,\n",
    "    max_tokens=50,\n",
    "    start_token=fra_vocab['<sos>'],\n",
    "    tgt_vocab=fra_vocab,\n",
    "    end_token=fra_vocab['<eos>'],\n",
    "    device=device\n",
    ")\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=torch.rand((27,1,50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq,n,em=l.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.7594, 0.2821, 0.0959,  ..., 0.9308, 0.7382, 0.4747],\n",
       "         [0.5889, 0.0044, 0.6634,  ..., 0.2076, 0.5865, 0.8355],\n",
       "         [0.4105, 0.1199, 0.9600,  ..., 0.0649, 0.1990, 0.4409],\n",
       "         ...,\n",
       "         [0.7169, 0.5462, 0.5273,  ..., 0.3649, 0.0948, 0.8626],\n",
       "         [0.3013, 0.6027, 0.5353,  ..., 0.5057, 0.2280, 0.9400],\n",
       "         [0.1132, 0.8083, 0.5205,  ..., 0.2114, 0.0280, 0.5455]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.reshape(n,seq,em)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "practice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
